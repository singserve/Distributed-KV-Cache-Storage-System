VCache logging: Log file configured from environment: log.txt (level: DEBUG)
VCache logging: Log level set from environment: DEBUG
2026-01-04 07:02:58 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:11 - CuPy is available
2026-01-04 07:02:58 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:20 - NVLINK transfer engine is available
2026-01-04 07:02:59 - lmcache.vcache.mooncake_transfer_engine - INFO - mooncake_transfer_engine.py:23 - Mooncake transfer engine is available
2026-01-04 07:02:59 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:28 - Mooncake transfer engine is available
2026-01-04 07:02:59 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:23 - Mooncake store is available
Cross-GPU Store and Retrieve Test
Store on GPU0, Retrieve on GPU1
============================================================
================================================================================
Cross-GPU Store and Retrieve Test
Store on GPU0, Retrieve on GPU1
================================================================================
Available GPUs: 2

1. Creating configuration for GPU0...
✓ Successfully loaded config from file: ./vcache_config_gpu0.yaml

2. Creating configuration for GPU1...
✓ Successfully loaded config from file: ./vcache_config_gpu1.yaml

3. Creating metadata...

4. Creating test data...
Number of tokens: 512
Number of blocks: 32
Slot mapping data length: 512
Slot mapping sample: [285, 390, 212, 378, 240]... (random mapping)
Sample slots to check: [285, 390, 212, 378, 240]
KV cache template created on GPU0
KV cache[0] address: 0x7f647ba00000

5. Setting up inter-process communication...

6. Starting processes...

7. Waiting for processes to complete...
VCache logging: Log file configured from environment: log.txt (level: DEBUG)
VCache logging: Log level set from environment: DEBUG
VCache logging: Log file configured from environment: log.txt (level: DEBUG)
VCache logging: Log level set from environment: DEBUG
2026-01-04 07:03:01 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:11 - CuPy is available
2026-01-04 07:03:01 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:20 - NVLINK transfer engine is available
2026-01-04 07:03:01 - lmcache.vcache.mooncake_transfer_engine - INFO - mooncake_transfer_engine.py:23 - Mooncake transfer engine is available
2026-01-04 07:03:01 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:28 - Mooncake transfer engine is available
2026-01-04 07:03:01 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:23 - Mooncake store is available
2026-01-04 07:03:01 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:11 - CuPy is available
2026-01-04 07:03:01 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:20 - NVLINK transfer engine is available
2026-01-04 07:03:01 - lmcache.vcache.mooncake_transfer_engine - INFO - mooncake_transfer_engine.py:23 - Mooncake transfer engine is available
2026-01-04 07:03:01 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:28 - Mooncake transfer engine is available
2026-01-04 07:03:01 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:23 - Mooncake store is available
[Retrieve Process GPU1] Starting retrieve process...
[Store Process GPU0] Starting store process...
[Store Process GPU0] Store KV cache created using generate_kv_cache_paged_list_tensors on GPU0
[Store Process GPU0] Store KV cache[0] address: 0x7fdd63e01000
[Store Process GPU0] Store KV cache shape: torch.Size([2, 32, 16, 8, 64])
[Store Process GPU0] Creating VCacheEngine...
2026-01-04 07:03:01 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:46 - Creating VCacheEngine with config: VCacheConfig(connector_role='worker', enable_gpu_vram_pool=True, use_vram_metadata_server=True, max_gpu_vram_metadata_size=10000, gpu_vram_segment_size_mb=256, enable_gpu_vram_segments=True, local_hostname='192.168.1.86:12345', global_segment_size=631242752, local_buffer_size=631242752, master_server_address='192.168.1.86:50051', metadata_server='http://192.168.1.86:8080/metadata', vram_metadata_ipc_address='192.168.1.86', vram_metadata_ipc_port=9091, transfer_engine_type='nvlink', gpu_id=0, max_concurrent_transfers=8, transfer_timeout_sec=30, local_hostname_TE='192.168.1.86:13245', protocol='tcp', protocol_TE='nvlink', device_name='')
2026-01-04 07:03:01 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:57 - GPU VRAM pool manager is initializing...
2026-01-04 07:03:01 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:64 - Using centralized VRAM metadata server via IPC
[Retrieve Process GPU1] Waiting for store process on GPU0 to complete...
2026-01-04 07:03:01 - lmcache.vcache.vram_metadata_ipc_client - INFO - vram_metadata_ipc_client.py:94 - Connection test successful: {'status': 'healthy', 'server_running': True, 'timestamp': 1767531781.6868386, 'address': '192.168.1.86', 'port': 9091}
2026-01-04 07:03:01 - lmcache.vcache.vram_metadata_ipc_client - INFO - vram_metadata_ipc_client.py:99 - Successfully connected to IPC server on attempt 1
2026-01-04 07:03:01 - lmcache.vcache.vram_metadata_ipc_client - INFO - vram_metadata_ipc_client.py:57 - VRAM Metadata IPC Client initialized for server: 192.168.1.86:9091
2026-01-04 07:03:01 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:69 - VRAM metadata IPC client connected successfully
2026-01-04 07:03:01 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:51 - Initializing transfer engine: type=nvlink, gpu_id=0
2026-01-04 07:03:01 - lmcache.vcache.nvlink_transfer_engine - DEBUG - nvlink_transfer_engine.py:160 - GPU 0 can access GPU 1 (peer access enabled)
2026-01-04 07:03:01 - lmcache.vcache.nvlink_transfer_engine - DEBUG - nvlink_transfer_engine.py:107 - Loaded native nvlink helper: ./native/build/libnvlink_transfer.so
2026-01-04 07:03:01 - lmcache.vcache.nvlink_transfer_engine - INFO - nvlink_transfer_engine.py:182 - Initializing NVLINK transfer engine for 2 GPUs
2026-01-04 07:03:01 - lmcache.vcache.nvlink_transfer_engine - DEBUG - nvlink_transfer_engine.py:191 - Peer access already enabled from GPU 0 to GPU 1
2026-01-04 07:03:01 - lmcache.vcache.nvlink_transfer_engine - DEBUG - nvlink_transfer_engine.py:191 - Peer access already enabled from GPU 1 to GPU 0
2026-01-04 07:03:01 - lmcache.vcache.nvlink_transfer_engine - INFO - nvlink_transfer_engine.py:222 - Transfer worker thread started
2026-01-04 07:03:01 - lmcache.vcache.nvlink_transfer_engine - INFO - nvlink_transfer_engine.py:218 - Transfer worker thread started
2026-01-04 07:03:01 - lmcache.vcache.nvlink_transfer_engine - INFO - nvlink_transfer_engine.py:93 - Distributed NVLINK Transfer Engine initialized for GPU 0. NVLINK available: True
2026-01-04 07:03:01 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:77 - NVLINK transfer engine initialized successfully for GPU 0
2026-01-04 07:03:01 - lmcache.vcache.gpu_vram_segment_manager - INFO - gpu_vram_segment_manager.py:620 - Allocated GPU VRAM segment on GPU 0: 256MB, address: 0x7fdd3c000000, segment_id: gpu_0_segment_0
2026-01-04 07:03:02 - lmcache.vcache.vram_metadata_ipc_client - INFO - vram_metadata_ipc_client.py:413 - Registered segment IPC handle via IPC: gpu_0_segment_0 @ 0x7fdd3c000000
2026-01-04 07:03:02 - lmcache.vcache.nvlink_transfer_engine - DEBUG - nvlink_transfer_engine.py:1137 - Registered segment gpu_0_segment_0 via IPC client
2026-01-04 07:03:02 - lmcache.vcache.gpu_vram_segment_manager - DEBUG - gpu_vram_segment_manager.py:634 - Registered segment gpu_0_segment_0 via transfer engine manager
2026-01-04 07:03:02 - lmcache.vcache.gpu_vram_segment_manager - DEBUG - gpu_vram_segment_manager.py:573 - Initialized GPU VRAM segments for GPU 0
2026-01-04 07:03:02 - lmcache.vcache.gpu_vram_segment_manager - INFO - gpu_vram_segment_manager.py:566 - GPU VRAM Segment Manager initialized for GPU 0
2026-01-04 07:03:02 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:67 - Using HTTP metadata server: http://192.168.1.86:8080/metadata
2026-01-04 07:03:02 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:82 - Using TCP protocol with device: 
2026-01-04 07:03:02 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:84 - Initializing Mooncake store with enhanced metadata config:
2026-01-04 07:03:02 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:85 -   local_hostname: 192.168.1.86:12345
2026-01-04 07:03:02 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:86 -   metadata_server: http://192.168.1.86:8080/metadata
2026-01-04 07:03:02 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:87 -   protocol: tcp
2026-01-04 07:03:02 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:88 -   device_name: 
2026-01-04 07:03:02 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:89 -   global_segment_size: 631242752 bytes
2026-01-04 07:03:02 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:90 -   local_buffer_size: 631242752 bytes
2026-01-04 07:03:02 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:91 -   master_server_address: 192.168.1.86:50051
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0104 07:03:02.123785  8621 client_metric.cpp:76] Client metrics enabled (default enabled)
I0104 07:03:02.125432  8621 ha_helper.cpp:20] Master view key: mooncake-store/mooncake/master_view
I0104 07:03:02.125466  8621 client.cpp:46] client_id=14935585208548400495-13846075195311910583
I0104 07:03:02.125489  8621 client.cpp:54] Client metrics enabled but reporting disabled (interval=0)
I0104 07:03:02.127100  8621 client.cpp:373] Storage root directory is not set. persisting data is disabled.
I0104 07:03:02.142773  8621 transfer_engine.cpp:486] Metrics reporting is disabled (set MC_TE_METRIC=1 to enable)
I0104 07:03:02.142822  8621 transfer_engine.cpp:91] Transfer Engine parseHostNameWithPort. server_name: 192.168.1.86 port: 12345
I0104 07:03:02.143234  8621 transfer_metadata_plugin.cpp:1127] Found active interface enp1s0f0 with IP 192.168.1.86
I0104 07:03:02.143249  8621 transfer_metadata_plugin.cpp:1116] Skipping interface docker0 (not UP or not RUNNING)
I0104 07:03:02.143285  8621 transfer_engine.cpp:146] Transfer Engine RPC using new RPC mapping, listening on 192.168.1.86:16856
I0104 07:03:02.143828  8621 client.cpp:268] Transfer engine auto discovery is disabled for protocol: tcp
I0104 07:03:02.144162  8621 tcp_transport.cpp:311] TcpTransport: listen on port 15181
I0104 07:03:02.168031  8621 pybind_client.cpp:196] Registering local memory: 631242752 bytes
I0104 07:03:02.168473  8621 pybind_client.cpp:220] Mounting segment: 631242752 bytes, 631242752 of 631242752
2026-01-04 07:03:02 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:110 - Mooncake store client setup successful
2026-01-04 07:03:02 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:111 - Mooncake storage backend initialized for GPU 0
WARNING: Using builtin hash without PYTHONHASHSEED set. For production environments, set PYTHONHASHSEED=0 to ensure consistent hashing across processes.
2026-01-04 07:03:03 - lmcache.vcache.blocked_kv_paged_connector - INFO - blocked_kv_paged_connector.py:71 - BlockedKVPagedMemConnector initialized: layers=4, block_size=16, heads=8, head_size=64
2026-01-04 07:03:03 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:162 - VCacheEngine initialized for GPU 0 with connector_role=worker
[Store Process GPU0] Performing store operation...
2026-01-04 07:03:03 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:997 - Store operation: 512 tokens, kvcaches=4, slot_mapping=True, offset=0
2026-01-04 07:03:03 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:1024 - Processing chunk/prefix [0, 256): 256 tokens, key: CacheEngineKey(fmt='vllm', model_name='test_model', world_size=2, worker_id=0, chunk_hash=b'\xa8\xbf6l\x9dS\xe3\x0b\xffA\xcb\xf3\xfa\xb81s\x85E\x81\x8d\xb6\xc7\xd4]\xb3\xd7\xad\xaa\xe9LW\x87', dtype=torch.float16, request_configs=None, tags=None, _dtype_str='half')
2026-01-04 07:03:03 - lmcache.vcache.gpu_vram_segment_manager - DEBUG - gpu_vram_segment_manager.py:764 - Allocated 2097152 bytes in segment gpu_0_segment_0 on GPU 0, offset: 0, block_size: 2097152
2026-01-04 07:03:03 - lmcache.vcache.gpu_vram_segment_manager - DEBUG - gpu_vram_segment_manager.py:435 - Registered VRAM unit CacheEngineKey(fmt='vllm', model_name='test_model', world_size=2, worker_id=0, chunk_hash=b'\xa8\xbf6l\x9dS\xe3\x0b\xffA\xcb\xf3\xfa\xb81s\x85E\x81\x8d\xb6\xc7\xd4]\xb3\xd7\xad\xaa\xe9LW\x87', dtype=torch.float16, request_configs=None, tags=None, _dtype_str='half') in segment gpu_0_segment_0
2026-01-04 07:03:03 - lmcache.vcache.gpu_vram_segment_manager - INFO - gpu_vram_segment_manager.py:1043 - Created VRAM unit for flattened data: CacheEngineKey(fmt='vllm', model_name='test_model', world_size=2, worker_id=0, chunk_hash=b'\xa8\xbf6l\x9dS\xe3\x0b\xffA\xcb\xf3\xfa\xb81s\x85E\x81\x8d\xb6\xc7\xd4]\xb3\xd7\xad\xaa\xe9LW\x87', dtype=torch.float16, request_configs=None, tags=None, _dtype_str='half') at segment gpu_0_segment_0, offset 0, size 2097152 bytes, dtype torch.float16, elements: 1048576, original_shape: None
2026-01-04 07:03:03 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:1113 - Created VRAM Unit: CacheEngineKey(fmt='vllm', model_name='test_model', world_size=2, worker_id=0, chunk_hash=b'\xa8\xbf6l\x9dS\xe3\x0b\xffA\xcb\xf3\xfa\xb81s\x85E\x81\x8d\xb6\xc7\xd4]\xb3\xd7\xad\xaa\xe9LW\x87', dtype=torch.float16, request_configs=None, tags=None, _dtype_str='half') at segment gpu_0_segment_0, offset 0, size 2097152 bytes, shape (16, 32, 16, 8, 64), tokens 256
2026-01-04 07:03:03 - lmcache.vcache.blocked_kv_paged_connector - DEBUG - blocked_kv_paged_connector.py:300 - Initialized kvcaches pointer with 4 layers
2026-01-04 07:03:03 - lmcache.vcache.blocked_kv_paged_connector - DEBUG - blocked_kv_paged_connector.py:112 - KV cache pointers initialized: 4 layers, page_buffer_size=512
2026-01-04 07:03:03 - lmcache.vcache.blocked_kv_paged_connector - INFO - blocked_kv_paged_connector.py:397 - Using existing pointers for device cuda:0 in download
2026-01-04 07:03:03 - lmcache.vcache.blocked_kv_paged_connector - DEBUG - blocked_kv_paged_connector.py:243 - Reverse format conversion: torch.Size([2, 4, 256, 512]) -> torch.Size([4, 16, 2, 16, 8, 64])
2026-01-04 07:03:03 - lmcache.vcache.blocked_kv_paged_connector - DEBUG - blocked_kv_paged_connector.py:456 - Converted from Flash Attention format: torch.Size([2, 4, 256, 512]) -> torch.Size([4, 16, 2, 16, 8, 64])
2026-01-04 07:03:03 - lmcache.vcache.blocked_kv_paged_connector - INFO - blocked_kv_paged_connector.py:461 - Download completed: 256 tokens for all 4 layers
2026-01-04 07:03:03 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:1160 - Successfully downloaded blocked KV cache data: shape=torch.Size([4, 16, 2, 16, 8, 64]), device=cuda:0, dtype=torch.float16
2026-01-04 07:03:03 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:1198 - Copied flattened tensor to VRAM segment: 2097152 bytes
2026-01-04 07:03:03 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:1289 - Extracted chunk KV cache parameters: num_layers=4, block_size=16, num_heads=8, head_size=64
2026-01-04 07:03:03 - lmcache.vcache.vram_metadata_ipc_client - INFO - vram_metadata_ipc_client.py:211 - Successfully registered KV cache via IPC - Key: b'\xa8\xbf6l\x9dS\xe3\x0b\xffA\xcb\xf3\xfa\xb81s\x85E\x81\x8d\xb6\xc7\xd4]\xb3\xd7\xad\xaa\xe9LW\x87', GPU: 0, Segment offset: 0
2026-01-04 07:03:03 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:1314 - Successfully registered KV cache chunk in GPU VRAM pool: 256 tokens, GPU 0, segment=gpu_0_segment_0, address=0x7fdd3c000000, size=2097152 bytes, segment_offset=0, shape=torch.Size([4, 16, 2, 16, 8, 64]), dtype=torch.float16, key_chunk_hash=b'\xa8\xbf6l\x9dS\xe3\x0b\xffA\xcb\xf3\xfa\xb81s\x85E\x81\x8d\xb6\xc7\xd4]\xb3\xd7\xad\xaa\xe9LW\x87'
2026-01-04 07:03:03 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:313 - Mooncake store: 256 chunk tokens stored with key b'\xa8\xbf6l\x9dS\xe3\x0b\xffA\xcb\xf3\xfa\xb81s\x85E\x81\x8d\xb6\xc7\xd4]\xb3\xd7\xad\xaa\xe9LW\x87', data_size=2097152 bytes
2026-01-04 07:03:03 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:1226 - Successfully stored KV cache for chunk [0, 256): 256 tokens with unified cache key,
2026-01-04 07:03:03 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:1235 - Released CPU tensor memory for chunk 0:256
2026-01-04 07:03:03 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:1024 - Processing chunk/prefix [256, 512): 256 tokens, key: CacheEngineKey(fmt='vllm', model_name='test_model', world_size=2, worker_id=0, chunk_hash=b'\xd5-\xe2\x11Z#5\x91"\r\x8a;\x85\xbe\xa8>t\xe5\xb1\x04\xcc\x11X\x96\xc7s\\6\x1b[\xea\xbe', dtype=torch.float16, request_configs=None, tags=None, _dtype_str='half')
2026-01-04 07:03:04 - lmcache.vcache.gpu_vram_segment_manager - DEBUG - gpu_vram_segment_manager.py:764 - Allocated 2097152 bytes in segment gpu_0_segment_0 on GPU 0, offset: 2097152, block_size: 2097152
2026-01-04 07:03:04 - lmcache.vcache.gpu_vram_segment_manager - DEBUG - gpu_vram_segment_manager.py:435 - Registered VRAM unit CacheEngineKey(fmt='vllm', model_name='test_model', world_size=2, worker_id=0, chunk_hash=b'\xd5-\xe2\x11Z#5\x91"\r\x8a;\x85\xbe\xa8>t\xe5\xb1\x04\xcc\x11X\x96\xc7s\\6\x1b[\xea\xbe', dtype=torch.float16, request_configs=None, tags=None, _dtype_str='half') in segment gpu_0_segment_0
2026-01-04 07:03:04 - lmcache.vcache.gpu_vram_segment_manager - INFO - gpu_vram_segment_manager.py:1043 - Created VRAM unit for flattened data: CacheEngineKey(fmt='vllm', model_name='test_model', world_size=2, worker_id=0, chunk_hash=b'\xd5-\xe2\x11Z#5\x91"\r\x8a;\x85\xbe\xa8>t\xe5\xb1\x04\xcc\x11X\x96\xc7s\\6\x1b[\xea\xbe', dtype=torch.float16, request_configs=None, tags=None, _dtype_str='half') at segment gpu_0_segment_0, offset 2097152, size 2097152 bytes, dtype torch.float16, elements: 1048576, original_shape: None
2026-01-04 07:03:04 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:1113 - Created VRAM Unit: CacheEngineKey(fmt='vllm', model_name='test_model', world_size=2, worker_id=0, chunk_hash=b'\xd5-\xe2\x11Z#5\x91"\r\x8a;\x85\xbe\xa8>t\xe5\xb1\x04\xcc\x11X\x96\xc7s\\6\x1b[\xea\xbe', dtype=torch.float16, request_configs=None, tags=None, _dtype_str='half') at segment gpu_0_segment_0, offset 2097152, size 2097152 bytes, shape (16, 32, 16, 8, 64), tokens 256
2026-01-04 07:03:04 - lmcache.vcache.blocked_kv_paged_connector - DEBUG - blocked_kv_paged_connector.py:300 - Initialized kvcaches pointer with 4 layers
2026-01-04 07:03:04 - lmcache.vcache.blocked_kv_paged_connector - DEBUG - blocked_kv_paged_connector.py:112 - KV cache pointers initialized: 4 layers, page_buffer_size=512
2026-01-04 07:03:04 - lmcache.vcache.blocked_kv_paged_connector - INFO - blocked_kv_paged_connector.py:397 - Using existing pointers for device cuda:0 in download
2026-01-04 07:03:04 - lmcache.vcache.blocked_kv_paged_connector - DEBUG - blocked_kv_paged_connector.py:243 - Reverse format conversion: torch.Size([2, 4, 256, 512]) -> torch.Size([4, 16, 2, 16, 8, 64])
2026-01-04 07:03:04 - lmcache.vcache.blocked_kv_paged_connector - DEBUG - blocked_kv_paged_connector.py:456 - Converted from Flash Attention format: torch.Size([2, 4, 256, 512]) -> torch.Size([4, 16, 2, 16, 8, 64])
2026-01-04 07:03:04 - lmcache.vcache.blocked_kv_paged_connector - INFO - blocked_kv_paged_connector.py:461 - Download completed: 256 tokens for all 4 layers
2026-01-04 07:03:04 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:1160 - Successfully downloaded blocked KV cache data: shape=torch.Size([4, 16, 2, 16, 8, 64]), device=cuda:0, dtype=torch.float16
2026-01-04 07:03:04 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:1198 - Copied flattened tensor to VRAM segment: 2097152 bytes
2026-01-04 07:03:04 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:1289 - Extracted chunk KV cache parameters: num_layers=4, block_size=16, num_heads=8, head_size=64
2026-01-04 07:03:04 - lmcache.vcache.vram_metadata_ipc_client - INFO - vram_metadata_ipc_client.py:211 - Successfully registered KV cache via IPC - Key: b'\xd5-\xe2\x11Z#5\x91"\r\x8a;\x85\xbe\xa8>t\xe5\xb1\x04\xcc\x11X\x96\xc7s\\6\x1b[\xea\xbe', GPU: 0, Segment offset: 2097152
2026-01-04 07:03:04 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:1314 - Successfully registered KV cache chunk in GPU VRAM pool: 256 tokens, GPU 0, segment=gpu_0_segment_0, address=0x7fdd3c200000, size=2097152 bytes, segment_offset=2097152, shape=torch.Size([4, 16, 2, 16, 8, 64]), dtype=torch.float16, key_chunk_hash=b'\xd5-\xe2\x11Z#5\x91"\r\x8a;\x85\xbe\xa8>t\xe5\xb1\x04\xcc\x11X\x96\xc7s\\6\x1b[\xea\xbe'
2026-01-04 07:03:04 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:313 - Mooncake store: 256 chunk tokens stored with key b'\xd5-\xe2\x11Z#5\x91"\r\x8a;\x85\xbe\xa8>t\xe5\xb1\x04\xcc\x11X\x96\xc7s\\6\x1b[\xea\xbe', data_size=2097152 bytes
2026-01-04 07:03:04 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:1226 - Successfully stored KV cache for chunk [256, 512): 256 tokens with unified cache key,
2026-01-04 07:03:04 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:1235 - Released CPU tensor memory for chunk 256:512
2026-01-04 07:03:04 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:1238 - Store operation completed for 512 tokens
[Store Process GPU0] Store completed in 1.1984 seconds
[Store Process GPU0] Signaled retrieve process to start
[Retrieve Process GPU1] Store process completed, waiting for 1 second before starting retrieve...
[Retrieve Process GPU1] Starting retrieve after waiting...
[Retrieve Process GPU1] Retrieve KV cache created using generate_kv_cache_paged_list_tensors on GPU1
[Retrieve Process GPU1] Retrieve KV cache[0] address: 0x7f870ba01000
[Retrieve Process GPU1] Retrieve KV cache shape: torch.Size([2, 32, 16, 8, 64])
[Retrieve Process GPU1] Creating VCacheEngine...
2026-01-04 07:03:05 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:46 - Creating VCacheEngine with config: VCacheConfig(connector_role='worker', enable_gpu_vram_pool=True, use_vram_metadata_server=True, max_gpu_vram_metadata_size=10000, gpu_vram_segment_size_mb=256, enable_gpu_vram_segments=True, local_hostname='192.168.1.86:12346', global_segment_size=631242752, local_buffer_size=631242752, master_server_address='192.168.1.86:50051', metadata_server='http://192.168.1.86:8080/metadata', vram_metadata_ipc_address='192.168.1.86', vram_metadata_ipc_port=9091, transfer_engine_type='nvlink', gpu_id=1, max_concurrent_transfers=8, transfer_timeout_sec=30, local_hostname_TE='192.168.1.86:13246', protocol='tcp', protocol_TE='nvlink', device_name='')
2026-01-04 07:03:05 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:57 - GPU VRAM pool manager is initializing...
2026-01-04 07:03:05 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:64 - Using centralized VRAM metadata server via IPC
2026-01-04 07:03:05 - lmcache.vcache.vram_metadata_ipc_client - INFO - vram_metadata_ipc_client.py:94 - Connection test successful: {'status': 'healthy', 'server_running': True, 'timestamp': 1767531785.6108003, 'address': '192.168.1.86', 'port': 9091}
2026-01-04 07:03:05 - lmcache.vcache.vram_metadata_ipc_client - INFO - vram_metadata_ipc_client.py:99 - Successfully connected to IPC server on attempt 1
2026-01-04 07:03:05 - lmcache.vcache.vram_metadata_ipc_client - INFO - vram_metadata_ipc_client.py:57 - VRAM Metadata IPC Client initialized for server: 192.168.1.86:9091
2026-01-04 07:03:05 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:69 - VRAM metadata IPC client connected successfully
2026-01-04 07:03:05 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:51 - Initializing transfer engine: type=nvlink, gpu_id=1
2026-01-04 07:03:05 - lmcache.vcache.nvlink_transfer_engine - DEBUG - nvlink_transfer_engine.py:160 - GPU 0 can access GPU 1 (peer access enabled)
2026-01-04 07:03:05 - lmcache.vcache.nvlink_transfer_engine - DEBUG - nvlink_transfer_engine.py:107 - Loaded native nvlink helper: ./native/build/libnvlink_transfer.so
2026-01-04 07:03:05 - lmcache.vcache.nvlink_transfer_engine - INFO - nvlink_transfer_engine.py:182 - Initializing NVLINK transfer engine for 2 GPUs
2026-01-04 07:03:05 - lmcache.vcache.nvlink_transfer_engine - DEBUG - nvlink_transfer_engine.py:191 - Peer access already enabled from GPU 0 to GPU 1
2026-01-04 07:03:05 - lmcache.vcache.nvlink_transfer_engine - DEBUG - nvlink_transfer_engine.py:191 - Peer access already enabled from GPU 1 to GPU 0
2026-01-04 07:03:05 - lmcache.vcache.nvlink_transfer_engine - INFO - nvlink_transfer_engine.py:222 - Transfer worker thread started
2026-01-04 07:03:05 - lmcache.vcache.nvlink_transfer_engine - INFO - nvlink_transfer_engine.py:218 - Transfer worker thread started
2026-01-04 07:03:05 - lmcache.vcache.nvlink_transfer_engine - INFO - nvlink_transfer_engine.py:93 - Distributed NVLINK Transfer Engine initialized for GPU 1. NVLINK available: True
2026-01-04 07:03:05 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:77 - NVLINK transfer engine initialized successfully for GPU 1
2026-01-04 07:03:05 - lmcache.vcache.gpu_vram_segment_manager - INFO - gpu_vram_segment_manager.py:620 - Allocated GPU VRAM segment on GPU 1: 256MB, address: 0x7f86e8000000, segment_id: gpu_1_segment_0
2026-01-04 07:03:05 - lmcache.vcache.vram_metadata_ipc_client - INFO - vram_metadata_ipc_client.py:413 - Registered segment IPC handle via IPC: gpu_1_segment_0 @ 0x7f86e8000000
2026-01-04 07:03:06 - lmcache.vcache.nvlink_transfer_engine - DEBUG - nvlink_transfer_engine.py:1137 - Registered segment gpu_1_segment_0 via IPC client
2026-01-04 07:03:06 - lmcache.vcache.gpu_vram_segment_manager - DEBUG - gpu_vram_segment_manager.py:634 - Registered segment gpu_1_segment_0 via transfer engine manager
2026-01-04 07:03:06 - lmcache.vcache.gpu_vram_segment_manager - DEBUG - gpu_vram_segment_manager.py:573 - Initialized GPU VRAM segments for GPU 1
2026-01-04 07:03:06 - lmcache.vcache.gpu_vram_segment_manager - INFO - gpu_vram_segment_manager.py:566 - GPU VRAM Segment Manager initialized for GPU 1
2026-01-04 07:03:06 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:67 - Using HTTP metadata server: http://192.168.1.86:8080/metadata
2026-01-04 07:03:06 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:82 - Using TCP protocol with device: 
2026-01-04 07:03:06 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:84 - Initializing Mooncake store with enhanced metadata config:
2026-01-04 07:03:06 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:85 -   local_hostname: 192.168.1.86:12346
2026-01-04 07:03:06 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:86 -   metadata_server: http://192.168.1.86:8080/metadata
2026-01-04 07:03:06 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:87 -   protocol: tcp
2026-01-04 07:03:06 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:88 -   device_name: 
2026-01-04 07:03:06 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:89 -   global_segment_size: 631242752 bytes
2026-01-04 07:03:06 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:90 -   local_buffer_size: 631242752 bytes
2026-01-04 07:03:06 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:91 -   master_server_address: 192.168.1.86:50051
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0104 07:03:06.043473  8622 client_metric.cpp:76] Client metrics enabled (default enabled)
I0104 07:03:06.045109  8622 ha_helper.cpp:20] Master view key: mooncake-store/mooncake/master_view
I0104 07:03:06.045141  8622 client.cpp:46] client_id=1316946241249558254-13675593604598315407
I0104 07:03:06.045171  8622 client.cpp:54] Client metrics enabled but reporting disabled (interval=0)
I0104 07:03:06.046643  8622 client.cpp:373] Storage root directory is not set. persisting data is disabled.
I0104 07:03:06.046713  8622 transfer_engine.cpp:486] Metrics reporting is disabled (set MC_TE_METRIC=1 to enable)
I0104 07:03:06.046736  8622 transfer_engine.cpp:91] Transfer Engine parseHostNameWithPort. server_name: 192.168.1.86 port: 12346
I0104 07:03:06.047091  8622 transfer_metadata_plugin.cpp:1127] Found active interface enp1s0f0 with IP 192.168.1.86
I0104 07:03:06.047106  8622 transfer_metadata_plugin.cpp:1116] Skipping interface docker0 (not UP or not RUNNING)
I0104 07:03:06.047150  8622 transfer_engine.cpp:146] Transfer Engine RPC using new RPC mapping, listening on 192.168.1.86:15742
I0104 07:03:06.047787  8622 client.cpp:268] Transfer engine auto discovery is disabled for protocol: tcp
I0104 07:03:06.048193  8622 tcp_transport.cpp:311] TcpTransport: listen on port 16419
I0104 07:03:06.076009  8622 pybind_client.cpp:196] Registering local memory: 631242752 bytes
I0104 07:03:06.076505  8622 pybind_client.cpp:220] Mounting segment: 631242752 bytes, 631242752 of 631242752
2026-01-04 07:03:06 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:110 - Mooncake store client setup successful
2026-01-04 07:03:06 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:111 - Mooncake storage backend initialized for GPU 1
WARNING: Using builtin hash without PYTHONHASHSEED set. For production environments, set PYTHONHASHSEED=0 to ensure consistent hashing across processes.
2026-01-04 07:03:07 - lmcache.vcache.blocked_kv_paged_connector - INFO - blocked_kv_paged_connector.py:71 - BlockedKVPagedMemConnector initialized: layers=4, block_size=16, heads=8, head_size=64
2026-01-04 07:03:07 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:162 - VCacheEngine initialized for GPU 1 with connector_role=worker
[Retrieve Process GPU1] Performing retrieve operation...
2026-01-04 07:03:07 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:358 - Retrieve operation: 512 tokens,mask=True, kvcaches=4,slot_mapping=True
2026-01-04 07:03:07 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:380 - Generated chunk [0, 256): 256 tokens, key: CacheEngineKey(fmt='vllm', model_name='test_model', world_size=2, worker_id=0, chunk_hash=b'\xa8\xbf6l\x9dS\xe3\x0b\xffA\xcb\xf3\xfa\xb81s\x85E\x81\x8d\xb6\xc7\xd4]\xb3\xd7\xad\xaa\xe9LW\x87', dtype=torch.float16, request_configs=None, tags=None, _dtype_str='half')
2026-01-04 07:03:07 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:380 - Generated chunk [256, 512): 256 tokens, key: CacheEngineKey(fmt='vllm', model_name='test_model', world_size=2, worker_id=0, chunk_hash=b'\xd5-\xe2\x11Z#5\x91"\r\x8a;\x85\xbe\xa8>t\xe5\xb1\x04\xcc\x11X\x96\xc7s\\6\x1b[\xea\xbe', dtype=torch.float16, request_configs=None, tags=None, _dtype_str='half')
2026-01-04 07:03:07 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:395 - batch_get_entry - Got 2 entries, 2 non-None entries
2026-01-04 07:03:07 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:412 - GPU VRAM hit for chunk [0, 256), key: CacheEngineKey(fmt='vllm', model_name='test_model', world_size=2, worker_id=0, chunk_hash=b'\xa8\xbf6l\x9dS\xe3\x0b\xffA\xcb\xf3\xfa\xb81s\x85E\x81\x8d\xb6\xc7\xd4]\xb3\xd7\xad\xaa\xe9LW\x87', dtype=torch.float16, request_configs=None, tags=None, _dtype_str='half'), chunk_hash: b'\xa8\xbf6l\x9dS\xe3\x0b\xffA\xcb\xf3\xfa\xb81s\x85E\x81\x8d\xb6\xc7\xd4]\xb3\xd7\xad\xaa\xe9LW\x87',gpu_id: 0, needs_transfer: True
2026-01-04 07:03:07 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:412 - GPU VRAM hit for chunk [256, 512), key: CacheEngineKey(fmt='vllm', model_name='test_model', world_size=2, worker_id=0, chunk_hash=b'\xd5-\xe2\x11Z#5\x91"\r\x8a;\x85\xbe\xa8>t\xe5\xb1\x04\xcc\x11X\x96\xc7s\\6\x1b[\xea\xbe', dtype=torch.float16, request_configs=None, tags=None, _dtype_str='half'), chunk_hash: b'\xd5-\xe2\x11Z#5\x91"\r\x8a;\x85\xbe\xa8>t\xe5\xb1\x04\xcc\x11X\x96\xc7s\\6\x1b[\xea\xbe',gpu_id: 0, needs_transfer: True
2026-01-04 07:03:07 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:422 - Found 2 GPU VRAM hits out of 2 chunks needing retrieval
2026-01-04 07:03:07 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:445 - Found 2 continuous GPU VRAM hits from the beginning,covering tokens [0, 512)
2026-01-04 07:03:07 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:456 - Processing 0 local GPU VRAM hits and 2 remote GPU VRAM hits
2026-01-04 07:03:07 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:803 - Processing 2 remote GPU VRAM hits (needs transfer)
2026-01-04 07:03:07 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:815 - Processing remote hit chunk [0, 256): 256 tokens from GPU 0
2026-01-04 07:03:07 - lmcache.vcache.gpu_vram_segment_manager - DEBUG - gpu_vram_segment_manager.py:764 - Allocated 2097152 bytes in segment gpu_1_segment_0 on GPU 1, offset: 0, block_size: 2097152
2026-01-04 07:03:07 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:832 - Allocated segment space: 2097152 bytes at address 0x7f86e8000000 for remote GPU VRAM hit data
2026-01-04 07:03:07 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:184 - Starting cross-GPU transfer:GPU 0 -> GPU 1,size: 2097152 bytes
2026-01-04 07:03:07 - lmcache.vcache.transfer_engine_manager - DEBUG - transfer_engine_manager.py:185 - Obtained IPC mem handle for source buffer 0x7fdd3c000000 on GPU 0 via IPC client: segment base 0x7fdd3c000000, size 268435456
2026-01-04 07:03:07 - lmcache.vcache.nvlink_transfer_engine - DEBUG - nvlink_transfer_engine.py:522 - Submitted transfer request transfer_1767531787559_1: GPU 0 -> GPU 1, size: 2097152 bytes, sync: True
2026-01-04 07:03:07 - lmcache.vcache.nvlink_transfer_engine - DEBUG - nvlink_transfer_engine.py:254 - Started transfer transfer_1767531787559_1: GPU 0 -> GPU 1, size: 2097152 bytes
2026-01-04 07:03:07 - lmcache.vcache.nvlink_transfer_engine - DEBUG - nvlink_transfer_engine.py:436 - Direct transfer submitted asynchronously: GPU 0->1, size=2097152 bytes (2.00 MB)
2026-01-04 07:03:07 - lmcache.vcache.nvlink_transfer_engine - INFO - nvlink_transfer_engine.py:310 - Transfer transfer_1767531787559_1 completed synchronously: GPU 0 -> GPU 1, size: 2097152 bytes, time: 0.010s
2026-01-04 07:03:07 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:212 - Cross-GPU transfer successful: localhost:GPU 0 -> localhost:GPU 1, size: 2097152 bytes
2026-01-04 07:03:07 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:238 - Cross-GPU transfer completed: GPU 0 -> GPU 1, size: 2097152 bytes, src_offset: 0, dst_offset: 0
2026-01-04 07:03:07 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:854 - Successfully transferred 256 tokens from GPU 0 to segment space
2026-01-04 07:03:07 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:263 - Registering transferred entry in GPU VRAM pool: GPU 1, address: 0x7f86e8000000, segment_id: gpu_1_segment_0, segment_offset: 0
2026-01-04 07:03:07 - lmcache.vcache.vram_metadata_ipc_client - INFO - vram_metadata_ipc_client.py:211 - Successfully registered KV cache via IPC - Key: b'\xa8\xbf6l\x9dS\xe3\x0b\xffA\xcb\xf3\xfa\xb81s\x85E\x81\x8d\xb6\xc7\xd4]\xb3\xd7\xad\xaa\xe9LW\x87', GPU: 1, Segment offset: 0
2026-01-04 07:03:07 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:289 - Successfully registered transferred entry in GPU VRAM pool:256 tokens on GPU 1 at address 0x7f86e8000000 segment_id: gpu_1_segment_0 segment_offset: 0
2026-01-04 07:03:07 - lmcache.vcache.gpu_vram_segment_manager - DEBUG - gpu_vram_segment_manager.py:435 - Registered VRAM unit CacheEngineKey(fmt='vllm', model_name='test_model', world_size=2, worker_id=0, chunk_hash=b'\xa8\xbf6l\x9dS\xe3\x0b\xffA\xcb\xf3\xfa\xb81s\x85E\x81\x8d\xb6\xc7\xd4]\xb3\xd7\xad\xaa\xe9LW\x87', dtype=torch.float16, request_configs=None, tags=None, _dtype_str='half') in segment gpu_1_segment_0
2026-01-04 07:03:07 - lmcache.vcache.gpu_vram_segment_manager - INFO - gpu_vram_segment_manager.py:1043 - Created VRAM unit for flattened data: CacheEngineKey(fmt='vllm', model_name='test_model', world_size=2, worker_id=0, chunk_hash=b'\xa8\xbf6l\x9dS\xe3\x0b\xffA\xcb\xf3\xfa\xb81s\x85E\x81\x8d\xb6\xc7\xd4]\xb3\xd7\xad\xaa\xe9LW\x87', dtype=torch.float16, request_configs=None, tags=None, _dtype_str='half') at segment gpu_1_segment_0, offset 0, size 2097152 bytes, dtype torch.float16, elements: 1048576, original_shape: torch.Size([4, 16, 2, 16, 8, 64])
2026-01-04 07:03:07 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:905 - Restored tensor for chunk [0, 256): shape=torch.Size([4, 16, 2, 16, 8, 64])
2026-01-04 07:03:07 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:815 - Processing remote hit chunk [256, 512): 256 tokens from GPU 0
2026-01-04 07:03:07 - lmcache.vcache.gpu_vram_segment_manager - DEBUG - gpu_vram_segment_manager.py:764 - Allocated 2097152 bytes in segment gpu_1_segment_0 on GPU 1, offset: 2097152, block_size: 2097152
2026-01-04 07:03:07 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:832 - Allocated segment space: 2097152 bytes at address 0x7f86e8200000 for remote GPU VRAM hit data
2026-01-04 07:03:07 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:184 - Starting cross-GPU transfer:GPU 0 -> GPU 1,size: 2097152 bytes
2026-01-04 07:03:07 - lmcache.vcache.transfer_engine_manager - DEBUG - transfer_engine_manager.py:185 - Obtained IPC mem handle for source buffer 0x7fdd3c200000 on GPU 0 via IPC client: segment base 0x7fdd3c000000, size 268435456
2026-01-04 07:03:07 - lmcache.vcache.nvlink_transfer_engine - DEBUG - nvlink_transfer_engine.py:522 - Submitted transfer request transfer_1767531787979_2: GPU 0 -> GPU 1, size: 2097152 bytes, sync: True
2026-01-04 07:03:07 - lmcache.vcache.nvlink_transfer_engine - DEBUG - nvlink_transfer_engine.py:254 - Started transfer transfer_1767531787979_2: GPU 0 -> GPU 1, size: 2097152 bytes
2026-01-04 07:03:07 - lmcache.vcache.nvlink_transfer_engine - DEBUG - nvlink_transfer_engine.py:436 - Direct transfer submitted asynchronously: GPU 0->1, size=2097152 bytes (2.00 MB)
2026-01-04 07:03:07 - lmcache.vcache.nvlink_transfer_engine - INFO - nvlink_transfer_engine.py:310 - Transfer transfer_1767531787979_2 completed synchronously: GPU 0 -> GPU 1, size: 2097152 bytes, time: 0.002s
2026-01-04 07:03:07 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:212 - Cross-GPU transfer successful: localhost:GPU 0 -> localhost:GPU 1, size: 2097152 bytes
2026-01-04 07:03:07 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:238 - Cross-GPU transfer completed: GPU 0 -> GPU 1, size: 2097152 bytes, src_offset: 0, dst_offset: 0
2026-01-04 07:03:07 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:854 - Successfully transferred 256 tokens from GPU 0 to segment space
2026-01-04 07:03:07 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:263 - Registering transferred entry in GPU VRAM pool: GPU 1, address: 0x7f86e8200000, segment_id: gpu_1_segment_0, segment_offset: 2097152
2026-01-04 07:03:08 - lmcache.vcache.vram_metadata_ipc_client - INFO - vram_metadata_ipc_client.py:211 - Successfully registered KV cache via IPC - Key: b'\xd5-\xe2\x11Z#5\x91"\r\x8a;\x85\xbe\xa8>t\xe5\xb1\x04\xcc\x11X\x96\xc7s\\6\x1b[\xea\xbe', GPU: 1, Segment offset: 2097152
2026-01-04 07:03:08 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:289 - Successfully registered transferred entry in GPU VRAM pool:256 tokens on GPU 1 at address 0x7f86e8200000 segment_id: gpu_1_segment_0 segment_offset: 2097152
2026-01-04 07:03:08 - lmcache.vcache.gpu_vram_segment_manager - DEBUG - gpu_vram_segment_manager.py:435 - Registered VRAM unit CacheEngineKey(fmt='vllm', model_name='test_model', world_size=2, worker_id=0, chunk_hash=b'\xd5-\xe2\x11Z#5\x91"\r\x8a;\x85\xbe\xa8>t\xe5\xb1\x04\xcc\x11X\x96\xc7s\\6\x1b[\xea\xbe', dtype=torch.float16, request_configs=None, tags=None, _dtype_str='half') in segment gpu_1_segment_0
2026-01-04 07:03:08 - lmcache.vcache.gpu_vram_segment_manager - INFO - gpu_vram_segment_manager.py:1043 - Created VRAM unit for flattened data: CacheEngineKey(fmt='vllm', model_name='test_model', world_size=2, worker_id=0, chunk_hash=b'\xd5-\xe2\x11Z#5\x91"\r\x8a;\x85\xbe\xa8>t\xe5\xb1\x04\xcc\x11X\x96\xc7s\\6\x1b[\xea\xbe', dtype=torch.float16, request_configs=None, tags=None, _dtype_str='half') at segment gpu_1_segment_0, offset 2097152, size 2097152 bytes, dtype torch.float16, elements: 1048576, original_shape: torch.Size([4, 16, 2, 16, 8, 64])
2026-01-04 07:03:08 - vcache.vcache_engine_system - DEBUG - vcache_engine_system.py:905 - Restored tensor for chunk [256, 512): shape=torch.Size([4, 16, 2, 16, 8, 64])
2026-01-04 07:03:08 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:926 - Performing batch upload of 2 transferred chunks
2026-01-04 07:03:08 - lmcache.vcache.blocked_kv_paged_connector - DEBUG - blocked_kv_paged_connector.py:300 - Initialized kvcaches pointer with 4 layers
2026-01-04 07:03:08 - lmcache.vcache.blocked_kv_paged_connector - DEBUG - blocked_kv_paged_connector.py:112 - KV cache pointers initialized: 4 layers, page_buffer_size=512
2026-01-04 07:03:08 - lmcache.vcache.blocked_kv_paged_connector - DEBUG - blocked_kv_paged_connector.py:488 - Batch upload: 2 chunks
2026-01-04 07:03:08 - lmcache.vcache.blocked_kv_paged_connector - DEBUG - blocked_kv_paged_connector.py:497 - Processing chunk 0: 256 tokens
2026-01-04 07:03:08 - lmcache.vcache.blocked_kv_paged_connector - DEBUG - blocked_kv_paged_connector.py:181 - Format conversion: torch.Size([4, 16, 2, 16, 8, 64]) -> torch.Size([2, 4, 256, 512])
2026-01-04 07:03:08 - lmcache.vcache.blocked_kv_paged_connector - DEBUG - blocked_kv_paged_connector.py:332 - Converted to Flash Attention format: torch.Size([4, 16, 2, 16, 8, 64]) -> torch.Size([2, 4, 256, 512])
2026-01-04 07:03:08 - lmcache.vcache.blocked_kv_paged_connector - DEBUG - blocked_kv_paged_connector.py:340 - Using existing pointers for device cuda:1
2026-01-04 07:03:08 - lmcache.vcache.blocked_kv_paged_connector - INFO - blocked_kv_paged_connector.py:367 - Upload completed: 256 tokens for all 4 layers
2026-01-04 07:03:08 - lmcache.vcache.blocked_kv_paged_connector - DEBUG - blocked_kv_paged_connector.py:497 - Processing chunk 1: 256 tokens
2026-01-04 07:03:08 - lmcache.vcache.blocked_kv_paged_connector - DEBUG - blocked_kv_paged_connector.py:181 - Format conversion: torch.Size([4, 16, 2, 16, 8, 64]) -> torch.Size([2, 4, 256, 512])
2026-01-04 07:03:08 - lmcache.vcache.blocked_kv_paged_connector - DEBUG - blocked_kv_paged_connector.py:332 - Converted to Flash Attention format: torch.Size([4, 16, 2, 16, 8, 64]) -> torch.Size([2, 4, 256, 512])
2026-01-04 07:03:08 - lmcache.vcache.blocked_kv_paged_connector - DEBUG - blocked_kv_paged_connector.py:340 - Using existing pointers for device cuda:1
2026-01-04 07:03:08 - lmcache.vcache.blocked_kv_paged_connector - INFO - blocked_kv_paged_connector.py:367 - Upload completed: 256 tokens for all 4 layers
2026-01-04 07:03:08 - lmcache.vcache.blocked_kv_paged_connector - DEBUG - blocked_kv_paged_connector.py:514 - Batch upload completed: 2 batches, 512 total tokens for all 4 layers
2026-01-04 07:03:08 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:939 - Successfully uploaded 2 transferred chunks via batch upload
2026-01-04 07:03:08 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:951 - Marked 256 tokens for chunk [0, 256) as retrieved
2026-01-04 07:03:08 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:951 - Marked 256 tokens for chunk [256, 512) as retrieved
2026-01-04 07:03:08 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:953 - Processed 2 remote GPU VRAM hits via batch upload, copied 512 tokens
[Retrieve Process GPU1] Retrieve completed in 1.1559 seconds
[Retrieve Process GPU1] Retrieved tokens: 512/512
2026-01-04 07:03:08 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:1443 - TestCacheEngine closing and releasing all resources
2026-01-04 07:03:08 - lmcache.vcache.gpu_vram_segment_manager - INFO - gpu_vram_segment_manager.py:1061 - Shutting down GPU VRAM segment manager for GPU 1
2026-01-04 07:03:08 - lmcache.vcache.gpu_vram_segment_manager - DEBUG - gpu_vram_segment_manager.py:453 - Unregistered VRAM unit CacheEngineKey(fmt='vllm', model_name='test_model', world_size=2, worker_id=0, chunk_hash=b'\xa8\xbf6l\x9dS\xe3\x0b\xffA\xcb\xf3\xfa\xb81s\x85E\x81\x8d\xb6\xc7\xd4]\xb3\xd7\xad\xaa\xe9LW\x87', dtype=torch.float16, request_configs=None, tags=None, _dtype_str='half') from segment gpu_1_segment_0
2026-01-04 07:03:08 - lmcache.vcache.gpu_vram_segment_manager - DEBUG - gpu_vram_segment_manager.py:453 - Unregistered VRAM unit CacheEngineKey(fmt='vllm', model_name='test_model', world_size=2, worker_id=0, chunk_hash=b'\xd5-\xe2\x11Z#5\x91"\r\x8a;\x85\xbe\xa8>t\xe5\xb1\x04\xcc\x11X\x96\xc7s\\6\x1b[\xea\xbe', dtype=torch.float16, request_configs=None, tags=None, _dtype_str='half') from segment gpu_1_segment_0
2026-01-04 07:03:08 - lmcache.vcache.gpu_vram_segment_manager - DEBUG - gpu_vram_segment_manager.py:520 - Cleared all VRAM units from segment gpu_1_segment_0
2026-01-04 07:03:08 - lmcache.vcache.gpu_vram_segment_manager - INFO - gpu_vram_segment_manager.py:918 - Cleaned up segment gpu_1_segment_0 metadata on GPU 1, freed all allocated blocks, reset free list, cleared VRAM units
2026-01-04 07:03:08 - lmcache.vcache.gpu_vram_segment_manager - DEBUG - gpu_vram_segment_manager.py:928 - Released GPU tensor memory for segment gpu_1_segment_0
2026-01-04 07:03:08 - lmcache.vcache.gpu_vram_segment_manager - INFO - gpu_vram_segment_manager.py:1086 - GPU VRAM segment manager shutdown completed for GPU 1
2026-01-04 07:03:08 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:1449 - GPU VRAM segment manager shutdown completed
2026-01-04 07:03:08 - lmcache.vcache.vram_metadata_ipc_client - INFO - vram_metadata_ipc_client.py:684 - Shutting down VRAM Metadata IPC Client
2026-01-04 07:03:08 - lmcache.vcache.vram_metadata_ipc_client - INFO - vram_metadata_ipc_client.py:697 - VRAM Metadata IPC Client shutdown completed
2026-01-04 07:03:08 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:1457 - VRAM metadata IPC client shutdown completed
2026-01-04 07:03:08 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:233 - Shutting down transfer engine
2026-01-04 07:03:08 - lmcache.vcache.nvlink_transfer_engine - INFO - nvlink_transfer_engine.py:1072 - Shutting down NVLINK transfer engine
2026-01-04 07:03:08 - lmcache.vcache.nvlink_transfer_engine - INFO - nvlink_transfer_engine.py:265 - Transfer worker thread stopped
2026-01-04 07:03:08 - lmcache.vcache.nvlink_transfer_engine - INFO - nvlink_transfer_engine.py:1080 - Transfer worker thread stopped
2026-01-04 07:03:08 - lmcache.vcache.nvlink_transfer_engine - INFO - nvlink_transfer_engine.py:1088 - NVLINK transfer engine shutdown completed
2026-01-04 07:03:08 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:243 - Transfer engine shutdown completed successfully
2026-01-04 07:03:08 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:252 - Transfer engine shutdown completed
2026-01-04 07:03:08 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:1465 - Transfer engine manager shutdown completed
2026-01-04 07:03:08 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:457 - Closing Mooncake storage backend and releasing all resources
2026-01-04 07:03:09 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:462 - Mooncake store client closed successfully
2026-01-04 07:03:09 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:478 - Mooncake storage backend shutdown completed
2026-01-04 07:03:09 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:1473 - Storage backend closed
2026-01-04 07:03:09 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:1483 - GPU connector resources released
2026-01-04 07:03:09 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:1487 - TestCacheEngine closed and all resources released
[Store Process GPU0] Retrieve process completed
2026-01-04 07:03:09 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:1443 - TestCacheEngine closing and releasing all resources
2026-01-04 07:03:09 - lmcache.vcache.gpu_vram_segment_manager - INFO - gpu_vram_segment_manager.py:1061 - Shutting down GPU VRAM segment manager for GPU 0
2026-01-04 07:03:09 - lmcache.vcache.gpu_vram_segment_manager - DEBUG - gpu_vram_segment_manager.py:453 - Unregistered VRAM unit CacheEngineKey(fmt='vllm', model_name='test_model', world_size=2, worker_id=0, chunk_hash=b'\xa8\xbf6l\x9dS\xe3\x0b\xffA\xcb\xf3\xfa\xb81s\x85E\x81\x8d\xb6\xc7\xd4]\xb3\xd7\xad\xaa\xe9LW\x87', dtype=torch.float16, request_configs=None, tags=None, _dtype_str='half') from segment gpu_0_segment_0
[Retrieve Process GPU1] Retrieve process completed successfully
2026-01-04 07:03:09 - lmcache.vcache.gpu_vram_segment_manager - DEBUG - gpu_vram_segment_manager.py:453 - Unregistered VRAM unit CacheEngineKey(fmt='vllm', model_name='test_model', world_size=2, worker_id=0, chunk_hash=b'\xd5-\xe2\x11Z#5\x91"\r\x8a;\x85\xbe\xa8>t\xe5\xb1\x04\xcc\x11X\x96\xc7s\\6\x1b[\xea\xbe', dtype=torch.float16, request_configs=None, tags=None, _dtype_str='half') from segment gpu_0_segment_0
2026-01-04 07:03:09 - lmcache.vcache.gpu_vram_segment_manager - DEBUG - gpu_vram_segment_manager.py:520 - Cleared all VRAM units from segment gpu_0_segment_0
2026-01-04 07:03:09 - lmcache.vcache.gpu_vram_segment_manager - INFO - gpu_vram_segment_manager.py:918 - Cleaned up segment gpu_0_segment_0 metadata on GPU 0, freed all allocated blocks, reset free list, cleared VRAM units
2026-01-04 07:03:09 - lmcache.vcache.gpu_vram_segment_manager - DEBUG - gpu_vram_segment_manager.py:928 - Released GPU tensor memory for segment gpu_0_segment_0
2026-01-04 07:03:09 - lmcache.vcache.gpu_vram_segment_manager - INFO - gpu_vram_segment_manager.py:1086 - GPU VRAM segment manager shutdown completed for GPU 0
2026-01-04 07:03:09 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:1449 - GPU VRAM segment manager shutdown completed
2026-01-04 07:03:09 - lmcache.vcache.vram_metadata_ipc_client - INFO - vram_metadata_ipc_client.py:684 - Shutting down VRAM Metadata IPC Client
2026-01-04 07:03:09 - lmcache.vcache.vram_metadata_ipc_client - INFO - vram_metadata_ipc_client.py:697 - VRAM Metadata IPC Client shutdown completed
2026-01-04 07:03:09 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:1457 - VRAM metadata IPC client shutdown completed
2026-01-04 07:03:09 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:233 - Shutting down transfer engine
2026-01-04 07:03:09 - lmcache.vcache.nvlink_transfer_engine - INFO - nvlink_transfer_engine.py:1072 - Shutting down NVLINK transfer engine
2026-01-04 07:03:09 - lmcache.vcache.nvlink_transfer_engine - INFO - nvlink_transfer_engine.py:265 - Transfer worker thread stopped
2026-01-04 07:03:09 - lmcache.vcache.nvlink_transfer_engine - INFO - nvlink_transfer_engine.py:1080 - Transfer worker thread stopped
2026-01-04 07:03:09 - lmcache.vcache.nvlink_transfer_engine - INFO - nvlink_transfer_engine.py:1088 - NVLINK transfer engine shutdown completed
2026-01-04 07:03:09 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:243 - Transfer engine shutdown completed successfully
2026-01-04 07:03:09 - lmcache.vcache.transfer_engine_manager - INFO - transfer_engine_manager.py:252 - Transfer engine shutdown completed
2026-01-04 07:03:09 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:1465 - Transfer engine manager shutdown completed
2026-01-04 07:03:09 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:457 - Closing Mooncake storage backend and releasing all resources
2026-01-04 07:03:09 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:462 - Mooncake store client closed successfully
2026-01-04 07:03:09 - lmcache.vcache.mooncake_storage_backend - INFO - mooncake_storage_backend.py:478 - Mooncake storage backend shutdown completed
2026-01-04 07:03:09 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:1473 - Storage backend closed
2026-01-04 07:03:09 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:1483 - GPU connector resources released
2026-01-04 07:03:09 - vcache.vcache_engine_system - INFO - vcache_engine_system.py:1487 - TestCacheEngine closed and all resources released
[Store Process GPU0] Store process completed successfully

8. Collecting results...

9. Test Results:
----------------------------------------
Store Process (GPU0): SUCCESS
  Store time: 1.1984 seconds
  Store KV cache address: 0x7fdd63e01000
Retrieve Process (GPU1): SUCCESS
  Retrieve time: 1.1559 seconds
  Retrieve KV cache address: 0x7f870ba01000
  Retrieved tokens: 512/512

  Data Comparison (based on slot_mapping):
  Token/Slot           Store Value     Retrieve Value  Match     
  -------------------- --------------- --------------- ----------
  token_0_slot_285     0.92480469      0.92480469      ✓         
  token_1_slot_390     0.82226562      0.82226562      ✓         
  token_2_slot_212     0.52685547      0.52685547      ✓         
  token_3_slot_378     0.90673828      0.90673828      ✓         
  token_4_slot_240     0.37353516      0.37353516      ✓         

  Data Match Summary:
    All samples match: Yes
    Mismatch count: 0
  ✓ All data samples match perfectly!

10. Overall Test Result:
----------------------------------------
✓ CROSS-GPU STORE/RETRIEVE TEST PASSED

✓ CROSS-GPU TEST PASSED